{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import collections\n",
    "import string\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = '../../ALPR(old)/train_data_old/single'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = string.ascii_uppercase+string.digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = range(len(os.listdir(TRAIN_PATH)))\n",
    "train_idx, val_idx = train_test_split(n, train_size=0.8, test_size=0.2, random_state=8888)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = os.listdir(TRAIN_PATH)\n",
    "train_dirs = [dirs[i] for i in train_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "\n",
    "for file in train_dirs:\n",
    "    filename, file_extension = os.path.splitext(file)\n",
    "    gt = filename.split('_')[-1]\n",
    "    labels.append(gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'J': 2297,\n",
       " 'L': 1830,\n",
       " 'Y': 1851,\n",
       " '1': 7981,\n",
       " '7': 7759,\n",
       " '3': 8566,\n",
       " '2': 8478,\n",
       " 'B': 5315,\n",
       " 'W': 16670,\n",
       " 'X': 1924,\n",
       " '0': 5914,\n",
       " '5': 7992,\n",
       " '4': 6965,\n",
       " 'A': 2798,\n",
       " 'U': 1682,\n",
       " 'V': 1591,\n",
       " 'G': 1520,\n",
       " '8': 8697,\n",
       " '6': 8388,\n",
       " 'S': 1502,\n",
       " 'D': 1744,\n",
       " '9': 8577,\n",
       " 'M': 1774,\n",
       " 'C': 1747,\n",
       " 'K': 1804,\n",
       " 'P': 1890,\n",
       " 'R': 1463,\n",
       " 'H': 2469,\n",
       " 'N': 1817,\n",
       " 'F': 1295,\n",
       " 'Q': 1540,\n",
       " 'E': 1488,\n",
       " 'T': 1569,\n",
       " 'Z': 28,\n",
       " 'O': 2,\n",
       " 'I': 2}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_count = {} \n",
    "  \n",
    "for keys in labels: \n",
    "    for c in keys.upper():\n",
    "        char_count[c] = char_count.get(c, 0) + 1\n",
    "char_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_dict = {}\n",
    "for c in char_count:\n",
    "    # laplace smoothing\n",
    "    prior_dict[c] = (char_count[c] + 1) / (sum(char_count.values()) + 36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.01417623e-02, 3.82542367e-02, 1.25787069e-02, 1.25571187e-02,\n",
       "       1.07149282e-02, 9.32608930e-03, 1.09452020e-02, 1.77742597e-02,\n",
       "       2.15881697e-05, 1.65365380e-02, 1.29888821e-02, 1.31759796e-02,\n",
       "       1.27730004e-02, 1.30824308e-02, 2.15881697e-05, 1.36077430e-02,\n",
       "       1.10891232e-02, 1.05350268e-02, 1.08156730e-02, 1.12978088e-02,\n",
       "       1.21109632e-02, 1.14561220e-02, 1.19965459e-01, 1.38524089e-02,\n",
       "       1.33270968e-02, 2.08685640e-04, 4.25646746e-02, 5.74389235e-02,\n",
       "       6.10153636e-02, 6.16486166e-02, 5.01277300e-02, 5.75180801e-02,\n",
       "       6.03677185e-02, 5.58413989e-02, 6.25913000e-02, 6.17277732e-02,\n",
       "       2.77777778e-02])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prior_arr = np.array([])\n",
    "for c in classes:\n",
    "    prior_arr = np.append(prior_arr, prior_dict[c])\n",
    "\n",
    "prior_arr = np.append(prior_arr, np.mean(list(prior_dict.values())))\n",
    "prior_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('weights/prior.pkl', 'wb') as f:\n",
    "    pickle.dump(prior_arr, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
